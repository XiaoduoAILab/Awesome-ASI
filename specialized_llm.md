# Awesome Specialized LLM

## ğŸ§  åŒ»ç–—é¢†åŸŸ

è°·æ­Œå‘å¸ƒäº†é’ˆå¯¹åŒ»å­¦é¢†åŸŸå¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ç³»åˆ—ï¼Œå¦‚**Med-PaLM**ï¼ˆåŸºäºPaLMæ¶æ„ï¼ŒFine-tuneï¼‰ï¼Œä»¥åŠåç»­çš„**Med-PaLM 2**å’Œå¤šæ¨¡æ€ç‰ˆæœ¬**Med-PaLM M**ã€‚è¿™äº›æ¨¡å‹åœ¨åŒ»å­¦è€ƒè¯•é—®ç­”å’Œå®é™…è¯Šæ–­æ¨ç†ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¯é¦–æ‰¹é€šè¿‡ç¾å›½åŒ»å¸ˆæ‰§ç…§è€ƒè¯•ï¼ˆUSMLEï¼‰åŠåŒ»å­¦çŸ¥è¯†é—®ç­”è¾¾åˆ°ä¸“å®¶æ°´å¹³çš„LLMã€‚Microsoftçš„**BioGPT**ï¼ˆGPT-2æ¶æ„ï¼Œåœ¨1500ä¸‡ç¯‡PubMedæ–‡æ‘˜ä¸Šé¢„è®­ç»ƒï¼‰ä¸“ç”¨äºç”Ÿç‰©åŒ»å­¦æ–‡æœ¬çš„ç”Ÿæˆä¸æŒ–æ˜ï¼Œåœ¨å…³ç³»æŠ½å–å’ŒåŒ»ç–—é—®ç­”ä»»åŠ¡ä¸Šä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚æ–¯å¦ç¦ç­‰æå‡ºçš„**BioMedLM**ï¼ˆ2.7B GPTé£æ ¼æ¨¡å‹ï¼Œä»…ç”¨PubMedæ–‡æœ¬è®­ç»ƒï¼‰åœ¨åŒ»å­¦é€‰æ‹©é¢˜é—®ç­”ä¸Šå¯ä¸æ›´å¤§é€šç”¨æ¨¡å‹åŒ¹æ•Œã€‚æ–°è¿‘å‡ºç°çš„å¼€æºåŒ»å­¦é¢†åŸŸæ¨¡å‹æœ‰**BioMistral-7B**ï¼ˆåŸºäºMistralï¼Œé¢„è®­ç»ƒè‡ªPubMedå…¨æ–‡ï¼‰ã€**PMC-LLaMA-13B**ï¼ˆåœ¨480ä¸‡ç¯‡åŒ»å­¦è®ºæ–‡åŸºç¡€ä¸Šæ³¨å…¥çŸ¥è¯†ï¼‰å’Œ**MEDITRON**ç³»åˆ—ï¼ˆ7B/70Bè§„æ¨¡ï¼ŒåŸºäºLLaMA-2ï¼Œæ‰©å……åŒ»å­¦æ•°æ®é¢„è®­ç»ƒï¼‰ã€‚

### ğŸ“Œ ä»£è¡¨æ€§è®ºæ–‡

- **Singhal et al., 2023** â€“ *Large language models encode clinical knowledge*  ä½œè€…ä»‹ç»äº†Med-PaLMï¼ˆåœ¨PaLMä¸Šè¿›è¡ŒåŒ»å­¦é¢†åŸŸæç¤ºè°ƒä¼˜ï¼‰å¹¶è¯„æµ‹å…¶åœ¨å¤šåŒ»å­¦é—®ç­”æ•°æ®é›†ä¸Šçš„æ•ˆæœï¼Œæå‡ºäº†äººç±»è¯„ä¼°æ¡†æ¶ï¼Œè¯æ˜äº†LLMåœ¨åŒ»å­¦é¢†åŸŸçš„æ½œåŠ›ã€‚ 
- **Luo et al., 2023** â€“ *BioGPT: A Generative Pre-trained Transformer for Biomedical Text*  å¾®è½¯ç ”ç©¶å‘˜æå‡ºBioGPTï¼ˆGPT-2æ¶æ„ï¼‰ï¼Œåœ¨1500ä¸‡ç¯‡PubMedæ–‡æ‘˜ä¸Šé¢„è®­ç»ƒï¼Œç”¨äºç”Ÿç‰©åŒ»å­¦æ–‡æœ¬ç”Ÿæˆå’ŒæŒ–æ˜ï¼Œåœ¨ç”Ÿç‰©åŒ»å­¦å…³ç³»æå–ä¸é—®ç­”ä¸Šå–å¾—äº†ä¼˜å¼‚æ€§èƒ½ã€‚ 
- **Bolton et al., 2024** â€“ *BioMedLM: A 2.7B Parameter Language Model Trained on Biomedical Text*  æ¥è‡ªæ–¯å¦ç¦å’ŒDatabricksï¼Œè®¾è®¡äº†ä¸€ä¸ª2.7Bçš„è‡ªå›å½’åŒ»å­¦LLMï¼Œä»…ä½¿ç”¨PubMedè¯­æ–™è®­ç»ƒï¼Œå®éªŒè¯æ˜å…¶åœ¨åŒ»å­¦å¤šé€‰é¢˜é—®ç­”ï¼ˆå¦‚MedMCQAç­‰ï¼‰ä¸Šè¡¨ç°è¶…è¿‡è®¸å¤šæ›´å¤§æ¨¡å‹ã€‚
- **Wu et al., 2023** â€“ *BloombergGPT* å°½ç®¡ä¸»è¦é’ˆå¯¹é‡‘èé¢†åŸŸï¼Œæ­¤æ–‡ä¸­æåˆ°â€œBloombergGPTâ€æ¨¡å‹ä»¥50Bå‚æ•°åœ¨3630äº¿é‡‘èç‰¹å®šè¯æ–™ä¸Šè®­ç»ƒï¼Œæœ¬åŸŸæ¨¡å‹çš„æˆåŠŸè¯´æ˜äº†è¡Œä¸šå®šåˆ¶LLMçš„æ½œåŠ›ï¼ˆæ­¤å¤„é‡‘èé¢†åŸŸå‚è€ƒï¼Œè¯æ˜äº†é¢†åŸŸé¢„è®­ç»ƒæ–¹å¼ï¼‰ã€‚ 
- **Labrak et al., 2024** â€“ *BioMistral*  è¯¥å·¥ä½œä»‹ç»äº†BioMistral-7Bï¼ˆåŸºäºMistral-7Bï¼Œåœ¨PubMed Centralä¸Šç»§ç»­é¢„è®­ç»ƒçš„å¼€æ”¾æºåŒ»å­¦æ¨¡å‹ï¼‰ï¼Œå¹¶åœ¨åŒ»å­¦QAä»»åŠ¡ä¸­ä¼˜äºç°æœ‰å¼€æºæ¨¡å‹ã€‚ 
- **Wu et al., 2023** â€“ *PMC-LLaMA*  è¯¥å›¢é˜ŸåŸºäºLLaMA-13Bï¼Œé€šè¿‡å¤§é‡åŒ»å­¦æ–‡çŒ®å’ŒæŒ‡å—æ³¨å…¥çŸ¥è¯†å¹¶è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œæ„å»ºäº†PMC-LLaMAç³»åˆ—ï¼Œç»“æœåœ¨åŒ»å­¦é—®ç­”è¯„æµ‹ä¸­è¶…è¿‡äº†ChatGPTã€‚ 
- **Chen et al., 2023** â€“ *MEDITRON-70B*  æå‡ºäº†MEDITRON-7B/70Bï¼Œåœ¨LLaMA-2åŸºç¡€ä¸Šè¿›è¡ŒåŒ»å­¦ä¸“ç”¨é¢„è®­ç»ƒï¼Œä½¿ç”¨PubMedå’Œä¸´åºŠæŒ‡å—ç­‰æ•°æ®ï¼Œæ˜¾è‘—è¶…è¿‡åŸºçº¿å¹¶æ¥è¿‘GPT-4æ°´å¹³ï¼Œå¼€æºäº†æƒé‡ã€‚ 

---

## âš–ï¸ æ³•å¾‹é¢†åŸŸ

è¿‘æœŸå‡ºç°å¤šæ¬¾æ³•å¾‹é¢†åŸŸä¸“ç”¨LLMã€‚ä¾‹å¦‚SaulLM-7Bï¼ˆEquall.aiå›¢é˜Ÿï¼Œ7Bå‚æ•°åŸºäºMistralæ¨¡å‹ï¼Œå¯¹3.0äº¿ç¯‡æ³•å¾‹æ–‡æ¡£å¾®è°ƒï¼‰ç”¨äºæ³•å¾‹æ–‡æœ¬ç†è§£ä¸ç”Ÿæˆï¼Œé‡‡ç”¨æŒ‡ä»¤å¾®è°ƒå®ç°é«˜æ•ˆé—®ç­”ä¸æ–‡ä¹¦å†™ä½œã€‚å¦ä¸€ä¸ªæ˜¯LawLLMï¼ˆCIKMâ€™24ï¼‰ï¼Œåœ¨Gemma-7BåŸºç¡€ä¸Šé€šè¿‡å¤šä»»åŠ¡è®­ç»ƒé€‚åº”ç¾å›½æ³•å¾‹åœºæ™¯ï¼Œæ¶µç›–æ¡ˆä»¶å®¡æŸ¥ã€åˆ¤å†³é¢„æµ‹ã€æ³•å¾‹æŸ¥è¯¢ç­‰ä»»åŠ¡ï¼Œé›†æˆæ£€ç´¢å’Œç¿»è¯‘æœºåˆ¶ï¼Œæ€§èƒ½ä¼˜äºå¤šé¡¹åŸºçº¿ã€‚ä¸­å›½æ–¹é¢ï¼Œæœ€é«˜äººæ°‘æ³•é™¢ä¼šåŒæ¸…åå¤§å­¦æ„å»ºäº†â€œæ³•ä¿¡æ³•å¾‹å¤§æ¨¡å‹â€ï¼Œåœ¨é€šç”¨100Bæ¨¡å‹ä¸Šå¾®è°ƒäº¿çº§æ³•å¾‹æ–‡çŒ®ï¼ˆæ–°é—»æŠ¥é“ï¼‰ã€‚å¦å¤§ç­‰æå‡ºLegalGPTï¼ˆICCä¼šè®®ï¼‰ï¼Œåˆ©ç”¨æ³•å¾‹é¢†åŸŸçš„é“¾å¼æ€ç»´ï¼ˆCoTï¼‰å’Œå¤šæ™ºèƒ½ä½“æ¡†æ¶æ”¹è¿›æ³•å¾‹æ¨ç†ï¼Œåœ¨æ³•å¾‹è€ƒè¯•ä¸å’¨è¯¢ä»»åŠ¡ä¸Šæ•ˆæœæ˜¾è‘—ã€‚


### ğŸ“Œ ä»£è¡¨æ€§è®ºæ–‡

- **Colombo et al., 2023** â€“ *SaulLM-7B*  ä»‹ç»SaulLM-7Bï¼ˆæ³•å¾‹å¤§æ¨¡å‹ï¼‰ï¼ŒåŸºäºMistral-7Bï¼Œåœ¨30Bæ³•å¾‹è¯­æ–™ä¸Šè®­ç»ƒå¹¶è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œå¼€æºç”¨äºæ³•å¾‹åˆè§„ç­‰åœºæ™¯ã€‚
- **Demetrey et al., 2024** â€“ *LawLLM*  æå‡ºLawLLMï¼Œå¤šä»»åŠ¡å¤šé˜¶æ®µè®­ç»ƒé€‚åº”ç¾å›½æ³•å¾‹é—®ç­”ï¼ŒåŒ…æ‹¬æ¡ˆä¾‹æ£€ç´¢ã€åˆ¤å†³é¢„æµ‹ç­‰ï¼Œç»“åˆé¢†åŸŸæ£€ç´¢ä¸ç¿»è¯‘æ–¹æ³•ï¼Œåœ¨å„é¡¹æ³•å¾‹ä»»åŠ¡ä¸Šè¶…è¿‡äº†é€šç”¨LLMåŸºçº¿ã€‚ 
- **çŸ³é•Œé“­ç­‰, 2024** â€“ *LegalGPT*  é‡‡ç”¨å¤šæ­¥æ¨ç†å’Œå¤šæ™ºèƒ½ä½“æœºåˆ¶å°†æ³•å¾‹é¢†åŸŸçŸ¥è¯†æ³¨å…¥LLMï¼Œé€šè¿‡æ„é€ æ³•å¾‹æ¨ç†é“¾æ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹æ³•å¾‹è€ƒè¯•é¢˜å’Œå’¨è¯¢ä»»åŠ¡çš„å›ç­”å‡†ç¡®ç‡ã€‚ 

---

## ğŸ’° é‡‘èé¢†åŸŸ

BloombergGPTï¼ˆ50Bå‚æ•°ï¼Œè®­ç»ƒäºBloombergå†…éƒ¨é‡‘èæ•°æ®é›†ï¼‰æ˜¯é¦–ä¸ªå¤§è§„æ¨¡é‡‘èä¸“ç”¨LLMï¼Œä½¿ç”¨3630äº¿è´¢ç»è¯æ–™è®­ç»ƒï¼Œå¹¶ä¸é€šç”¨æ•°æ®æ··åˆè®­ç»ƒï¼Œå¯å¤§å¹…æå‡é‡‘èé—®ç­”ä¸åˆ†æä»»åŠ¡çš„è¡¨ç° ã€‚å¼€æºæ–¹é¢ï¼ŒFinGPTï¼ˆæ¨æ´ªæ´‹ç­‰ï¼Œ2023ï¼‰æ„å»ºäº†è´¢åŠ¡æ•°æ®ç®¡é“å¹¶åŸºäºä½ç§©é€‚é…æŠ€æœ¯è®­ç»ƒLLMï¼Œæ”¯æŒæœºå™¨äººæŠ•é¡¾ã€ç®—æ³•äº¤æ˜“ç­‰åº”ç”¨ ã€‚ä¸Šè¿°æ¨¡å‹ä¸“é—¨ç”¨äºè´¢åŠ¡é—®ç­”ã€å¸‚åœºåˆ†æç­‰ä»»åŠ¡ï¼Œå·²åº”ç”¨äºè¯åˆ¸åˆ†æä¸æ™ºèƒ½æŠ•ç ”ç­‰ç³»ç»Ÿä¸­ã€‚


### ğŸ“Œ ä»£è¡¨æ€§è®ºæ–‡

- **Wu et al., 2023** â€“ *BloombergGPT*  ä»‹ç»BloombergGPTï¼Œ50Bå‚æ•°é‡‘èä¸“ç”¨æ¨¡å‹ï¼Œåœ¨é‡‘èå’Œé€šç”¨å·¨é‡æ•°æ®ä¸Šè®­ç»ƒï¼Œæ˜¾è‘—æå‡è´¢åŠ¡é¢†åŸŸä»»åŠ¡æ€§èƒ½ã€‚ 
- **Yang et al., 2023** â€“ *FinGPT*  æå‡ºFinGPTæ¡†æ¶ï¼Œå¼ºè°ƒæ•°æ®ä¸­å¿ƒçš„æµæ°´çº¿å’ŒLLMé€‚é…æ–¹æ³•ï¼Œå¹¶æ¼”ç¤ºäº†åœ¨é‡åŒ–äº¤æ˜“ã€æŠ•é¡¾ç­‰åœºæ™¯çš„åº”ç”¨ã€‚ 

---

## ğŸ“ æ•™è‚²é¢†åŸŸ

åœ¨æ•™è‚²é¢†åŸŸï¼Œä¸»è¦æ˜¯åˆ©ç”¨ç°æœ‰å¤§å‹æ¨¡å‹è¿›è¡Œå®šåˆ¶åŒ–æœåŠ¡ã€‚ä¾‹å¦‚OpenAIæ¨å‡ºçš„ChatGPT Educationï¼ˆæ ¡å›­ç‰ˆï¼‰ï¼Œé¢å‘é«˜æ ¡ç”¨æˆ·å¼€æ”¾GPT-4oï¼Œå¢åŠ åˆ†æã€æµè§ˆã€æ–‡ä»¶æ€»ç»“ç­‰å·¥å…·ï¼Œæ”¯æŒç”Ÿæˆè¯¾å ‚æ•™ç¨‹ã€ä¸ªæ€§è¾…å¯¼ç­‰ã€‚è™½ç„¶ç›®å‰å°šæ— å…¬å¼€çš„â€œæ•™è‚²ä¸“ç”¨LLMâ€æ¨¡å‹è®ºæ–‡ï¼Œä½†æœ‰ç ”ç©¶æ¢è®¨å°†LLMä½œä¸ºæ•™å­¦åŠ©æ‰‹æˆ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåº”ç”¨äºæ•™è‚²ã€‚ä¾‹å¦‚Chenç­‰ï¼ˆ2025ï¼‰ç»¼è¿°äº†åŸºäºLLMçš„æ•™è‚²ä»£ç†ï¼Œæå‡ºå°†LLMç”¨äºè¯¾ç¨‹ç­”ç–‘ä¸ä¸ªæ€§åŒ–å­¦ä¹ ã€‚è¿™äº›å·¥å…·å·²åœ¨é«˜æ ¡è¯•ç‚¹ç”¨äºå­¦ä¹ è¾…å¯¼ã€ç­”ç–‘è§£æƒ‘å’Œç¼–ç¨‹æ•™è‚²ã€‚


### ğŸ“Œ ä»£è¡¨æ€§è®ºæ–‡

- **OpenAI, 2024** â€“ *ChatGPT Education*  æè¿°äº†é¢å‘å¤§å­¦çš„ChatGPTæ ¡å›­ç‰ˆæœåŠ¡ï¼Œæ‰©å±•äº†GPT-4oçš„ä½¿ç”¨é™é¢å’ŒåŠŸèƒ½ï¼Œä¸ºå¸ˆç”Ÿæä¾›è¾…å¯¼ã€æ–‡æœ¬åˆ†æå’Œå¤šè¯­è¨€æ”¯æŒã€‚ 
- **Zhendong et al., 2025** â€“ *LLM Agents for Education*  ç»¼è¿°æ€§è®ºæ–‡ï¼Œè®¨è®ºäº†LLMåœ¨æ•™è‚²ä¸­ä½œä¸ºæ™ºèƒ½æ•™å­¦ä»£ç†çš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬åœ¨è¯¾ç¨‹æ•™å­¦å’Œå­¦ä¹ åˆ†æä¸­çš„åº”ç”¨æ¡ˆä¾‹ã€‚ 

---

## ğŸ’» ç¼–ç¨‹é¢†åŸŸ

ä¼—å¤šä¸“é—¨é’ˆå¯¹ç¼–ç¨‹ä»»åŠ¡çš„LLMç›¸ç»§å‡ºç°ï¼šCodexï¼ˆOpenAIï¼ŒåŸºäºGPT-3åœ¨å…¬å¼€ä»£ç åº“ä¸Šå¾®è°ƒï¼‰å¯æ ¹æ®æ³¨é‡Šç”Ÿæˆä»£ç ï¼Œç”¨äºGitHub Copilotç­‰ç¼–ç¨‹åŠ©æ‰‹ï¼›StarCoderï¼ˆBigCodeå¼€æºç»„ç»‡ï¼Œ15.5Bå‚æ•°ï¼‰åœ¨GitHubè®¸å¯ä»£ç ä¸Šé¢„å‚æ•°ï¼‰åœ¨Llama-2æ¨¡å‹ä¸Šè¿›ä¸€æ­¥è®­ç»ƒäº†500Bä»£ç æ•°æ®ï¼Œå¼•å…¥ä¸­é—´å¡«å……èƒ½åŠ›ï¼Œå¹¶æä¾›ä¸“ä¸šçš„Pythonå’ŒæŒ‡ä»¤ç‰ˆæœ¬ï¼›CodeGeeXï¼ˆæ¸…åä¸åä¸ºï¼Œ13Bå‚æ•°ï¼‰åœ¨850Bå¤šè¯­è¨€ä»£ç æ•°æ®ä¸Šé¢„è®­ç»ƒï¼Œæ”¯æŒ24ç§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¶åœ¨HumanEval-Xç­‰å¤šè¯­ç§åŸºå‡†ä¸Šä¼˜äºåŒè§„æ¨¡æ¨¡å‹ ï¼›AlphaCodeï¼ˆDeepMindï¼Œé‡‡ç”¨Transformerè¶…å¤§æ¨¡å‹å’Œå¤§é‡é‡‡æ ·+ç­›é€‰ç­–ç•¥ï¼‰åœ¨ç«èµ›ç¼–ç¨‹é¢˜ä¸­å¯è§£å†³ç›¸å½“æ¯”ä¾‹çš„é—®é¢˜ï¼›CodeGenï¼ˆSalesforceï¼ŒICLRâ€™23ï¼‰æä¾›å¤šä¸ªè§„æ¨¡ï¼ˆæœ€é«˜16.1Bï¼‰çš„å¼€æºä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶æå‡ºåˆ†æ­¥åˆæˆèŒƒå¼ä»¥æé«˜å¤æ‚ç¨‹åºçš„ç”Ÿæˆè´¨é‡ ã€‚è¿™äº›æ¨¡å‹å¯ç”¨äºè‡ªåŠ¨è¡¥å…¨ã€ä»£ç è§£é‡Šã€ç®—æ³•ç”Ÿæˆç­‰ï¼Œå¹¶å·²é›†æˆåˆ°å¼€å‘å·¥å…·ä¸åœ¨çº¿IDEä¸­ï¼ˆå¦‚GitHub Copilotã€Metaçš„IDEæ’ä»¶ç­‰ï¼‰ã€‚


### ğŸ“Œ ä»£è¡¨æ€§è®ºæ–‡

- **Chen et al., 2021** â€“ *Codex*  é¦–æ¬¡ä»‹ç»äº†OpenAIçš„Codexï¼Œé€šè¿‡GitHubä»£ç å¾®è°ƒGPTæ¨¡å‹ï¼Œåœ¨åˆæˆç¨‹åºç”Ÿæˆä»»åŠ¡HumanEvalä¸­æ€§èƒ½è¿œè¶…GPT-3ï¼Œå¹¶è®¨è®ºäº†é‡‡æ ·ç­–ç•¥çš„é‡è¦æ€§ã€‚ 
- **Li et al., 2023** â€“ *StarCoder*  BigCodeå›¢é˜Ÿä»‹ç»äº†StarCoderï¼ˆ15.5Bï¼‰ï¼Œä½¿ç”¨1Tå¼€æºä»£ç è®­ç»ƒï¼Œå¹¶é€šè¿‡Pythonå¾®è°ƒï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šè¯­è¨€ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„é¢†å…ˆæ€§èƒ½ã€‚ 
- **Meta News, 2023** â€“ *Code Llama*  å®˜æ–¹å…¬å‘Šï¼Œæè¿°äº†Code Llamaï¼ˆ7B/13B/34Bï¼‰çš„è®­ç»ƒç»†èŠ‚ï¼Œ500Bä»£ç æ•°æ®ã€å¡«å……èƒ½åŠ›åŠä¸“é—¨çš„Pythonå’ŒæŒ‡ä»¤ç‰ˆæœ¬ï¼Œç”¨äºå¢å¼ºå¼€å‘è€…çš„ç¼–ç æ•ˆç‡ã€‚ 
- **Zheng et al., 2023** â€“ *CodeGeeX*  æ¸…åç­‰æå‡ºCodeGeeXï¼ˆ13Bï¼‰ï¼Œåœ¨850Bå¤šè¯­ç§ä»£ç ä¸Šè®­ç»ƒï¼Œå…¬æµ‹äº†HumanEval-XåŸºå‡†ï¼Œè¯æ˜å…¶åœ¨ä»£ç ç”Ÿæˆå’Œç¿»è¯‘ä»»åŠ¡ä¸Šçš„ç«äº‰åŠ›ï¼ŒåŒæ—¶å¼€æºäº†æ¨¡å‹å’Œå·¥å…·é“¾ã€‚ 
- **Nijkamp et al., 2023** â€“ *CodeGen*  ä»‹ç»Salesforceçš„CodeGenæ¨¡å‹ï¼ˆæœ€é«˜16.1Bï¼‰ï¼Œæå‡ºå¤šè½®æç¤ºæ–¹å¼æå‡å¤æ‚ç¨‹åºç”Ÿæˆï¼Œå¹¶å‘å¸ƒç›¸åº”åŸºå‡†å’Œå¼€æºä»£ç ã€‚

---

## ğŸ”¬ ç§‘ç ”é¢†åŸŸ

ç§‘å­¦ä¸“ç”¨LLMå¦‚**ChemCrow**ï¼ˆç»“åˆGPT-4ä¸åŒ–å­¦å·¥å…·ï¼‰ã€**MolecularGPT**ï¼ˆç”¨äºåˆ†å­å±æ€§é¢„æµ‹ï¼‰ã€**Galactica**ï¼ˆMetaå‡ºå“ï¼Œè®­ç»ƒäºç§‘å­¦çŸ¥è¯†ï¼‰ã€**GeoGalactica**ï¼ˆåœ°çƒç§‘å­¦æ–¹å‘ï¼‰ç­‰ï¼Œå±•ç°äº†LLMåœ¨ç§‘ç ”è‡ªåŠ¨åŒ–ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

### ğŸ“Œ ä»£è¡¨æ€§è®ºæ–‡

- **Bran et al., 2024** â€“ *ChemCrow*  ä»‹ç»äº†ChemCrowæ¡†æ¶ï¼Œå°†GPT-4ä¸ä¸“ä¸šåŒ–å­¦å·¥å…·æ•´åˆï¼Œç”¨äºæœ‰æœºåˆæˆå’Œææ–™å‘ç°ä»»åŠ¡ï¼Œå¹¶éªŒè¯äº†å…¶è‡ªåŠ¨åŒ–åŒ–å­¦é—®é¢˜è§£å†³èƒ½åŠ›ã€‚ 
- **Liu et al., 2024** â€“ *MolecularGPT*  æå‡ºé€šè¿‡åˆ†å­æŒ‡ä»¤å¾®è°ƒLLMçš„æ–¹æ³•æ¥é¢„æµ‹åˆ†å­æ€§è´¨ï¼Œå±•ç¤ºäº†MolecularGPTåœ¨æ–°åˆ†å­ä»»åŠ¡ä¸Šçš„é€šç”¨æ€§å’Œä¼˜ç§€æ€§èƒ½ã€‚ 
- **Taylor et al., 2022** â€“ *Galactica*  Metaå…¬å¸ƒGalacticaæ¨¡å‹ï¼Œè®­ç»ƒäºæµ·é‡ç§‘å­¦è®ºæ–‡å’ŒçŸ¥è¯†åº“ï¼Œåœ¨æ•°å­¦ã€åŒ–å­¦é—®ç­”åŠPubMedQAç­‰ä»»åŠ¡ä¸Šè¶…è¿‡GPT-3å’ŒBLOOMç­‰åŸºçº¿ï¼Œå±•ç¤ºäº†ä¸“ç”¨ç§‘å­¦LLMçš„æ½œåŠ›ã€‚ 
- **Lin et al., 2023** â€“ *GeoGalactica*  åœ¨GalacticaåŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥é¢„è®­ç»ƒå’Œå¾®è°ƒåœ°çƒç§‘å­¦é¢†åŸŸæ•°æ®ï¼Œæ„å»º30Bå‚æ•°åœ°è´¨å­¦æ¨¡å‹ï¼ŒéªŒè¯å…¶åœ¨åœ°è´¨è€ƒè¯•å’ŒçŸ¥è¯†æŸ¥è¯¢ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ã€‚ 

---

## ğŸ“š BibTeXå‚è€ƒæ–‡çŒ®ï¼ˆéƒ¨åˆ†ï¼‰

```bibtex
@article{singhal2025,
author = {Karan Singhal and Tao Tu and Joey Gottweis and Catherine T. Kelleher and ...},
title = {Toward expert-level medical question answering with large language models},
journal = {Nature Medicine},
volume = {31},
pages = {943--950},
year = {2025},
doi = {10.1038/s41591-024-03423-7}
}
@article{singhal2023,
author = {Karan Singhal and Shreya R. Mahdavi and ...},
title = {Large language models encode clinical knowledge},
journal = {Nature},
volume = {620},
pages = {172--180},
year = {2023},
doi = {10.1038/s41586-023-06291-2}
}
@article{luo2023,
author = {Renqian Luo and Yanyu Zhang and Jian An and ...},
title = {BioGPT: A Generative Pre-trained Transformer for Biomedical Text Generation and Mining},
journal = {arXiv preprint arXiv:2304.15142},
year = {2023}
}
@article{bolton2024,
author = {Elliot Bolton and Abhinav Venigalla and Sanjay Rama and ...},
title = {BioMedLM: A 2.7B Parameter Language Model Trained on Biomedical Text},
journal = {arXiv preprint arXiv:2403.01410},
year = {2024}
}
@article{wu2023,
author = {Shijie Wu and Ozan Irsoy and Steven Lu and Vadim Dabravolski and Mark Dredze and
Sebastian Gehrmann and Prabhanjan Kambadur and David Rosenberg and Gideon Mann},
title = {BloombergGPT: A Large Language Model for Finance},
journal = {arXiv preprint arXiv:2303.17564},
year = {2023}
}
@article{yang2023,
author = {Hongyang Yang and Xiao-Yang Liu and Christina Dan Wang},
title = {FinGPT: Open-Source Financial Large Language Models},
journal = {arXiv preprint arXiv:2306.06031},
year = {2023}
}
@article{chen2021,
author = {Mark Chen and Jerry Tworek and Heewoo Jun and ...},
title = {Evaluating Large Language Models Trained on Code},
journal = {arXiv preprint arXiv:2107.03374},
year = {2021}
}
@article{li2022,
author = {Yujia Li and Hanyu Liu and Daria Tsvyashchenko and ...},
title = {Competition-Level Code Generation with AlphaCode},
journal = {Science},
volume = {379},
pages = {270--274},
year = {2022}
}
@article{nijkamp2023,
author = {Erik Nijkamp and Bo Pang and Hiroaki Hayashi and ...},
title = {CODEGEN: An Open Large Language Model for Code with Multi-Turn Program Synthesis},
journal = {Proceedings of the International Conference on Learning Representations (ICLR)},
year = {2023}
}
@article{li2023starcoder,
author = {Raymond Li and Loubna Ben Allal and Yangtian Zi and ...},
title = {StarCoder: may the source be with you!},
journal = {arXiv preprint arXiv:2305.06161},
year = {2023}
}
@article{zhou2024,
author = {Zhouhan Lin and Cheng Deng and Le Zhou and ...},
title = {GeoGalactica: A Scientific Large Language Model in Geoscience},
journal = {arXiv preprint arXiv:2401.00434},
year = {2024}
}
@article{bran2024,
author = {Andres M. Bran and Sam Cox and Oliver Schilter and ...},
title = {Augmenting large language models with chemistry tools},
journal = {Nature Machine Intelligence},
volume = {6},
pages = {525--535},
year = {2024}
}
@article{liu2024,
author = {Yuyan Liu and Sirui Ding and Sheng Zhou and ...},
title = {MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property
Prediction},
journal = {arXiv preprint arXiv:2406.12950},
year = {2024}
}
@article{taylor2022,
author = {Ross Taylor and Marcin Kardas and Guillem Cucurull and ...},
title = {Galactica: A Large Language Model for Science},
journal = {arXiv preprint arXiv:2211.09085},
year = {2022}
}
@article{colombo2023,
author = {Pierre Colombo and Sergey Bobenko and Etienne Bergeron and ...},
title = {SaulLM-7B: A pioneering large language model for law},
journal = {arXiv preprint arXiv:2312.15175},
year = {2023}
}
@inproceedings{demetrey2024,
author = {Arthur Demetrey and Chuancheng Du and Minghuang Zhang and ...},
title = {LawLLM: Law Large Language Model for the US Legal System},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge
Management (CIKM)},
year = {2024}
}
@article{zhang2023,
author = {Quanyu Zhang and Han Xu and Yuan Liu and ...},
title = {LegalGPT: Legal Chain of Thought for the Legal Large Language Model Multi-Agent
Framework},
journal = {Proceedings of the International Conference on Intelligent Computing (ICC)},
year = {2024}
}
@misc{openai2024,
author = {OpenAI},
title = {ChatGPT Education},
howpublished = {\url{https://openai.com/chatgpt/education/}},
year = {2024}
}

```
